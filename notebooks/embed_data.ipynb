{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed tweet data and store in a ChromaDB vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook's goal is to store all the tweet data in the vector database. This data will then be used in the RAG system to answer customer's tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import os\n",
    "import configparser\n",
    "import pandas as pd\n",
    "\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "\n",
    "\n",
    "if not os.path.exists('../output'):\n",
    "    os.makedirs('../output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/twitter_data_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose we will build a tool for AmazonHelp customer service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.company == 'AmazonHelp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique id for each tweet\n",
    "df['id'] = [str(uuid.uuid4()) for tweet in df.company_tweet.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.customer_tweet.str.len() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data used for this project\n",
    "df.to_csv('../output/twitter_data_clean_Amazon.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/twitter_data_clean_Amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI API key from config.ini\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "openai_api_key = config['OPENAI_API']['OPENAI_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate embedding function to be used by ChromaDB when storing data\n",
    "\"\"\"\n",
    "The embedding function takes text as input, and performs tokenization and embedding. \n",
    "\"\"\"\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=openai_api_key,\n",
    "                model_name=\"text-embedding-3-small\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ChromaDB client, saving it in a sqlite3 database file \n",
    "client = chromadb.PersistentClient(path=\"../chromadb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(name=\"tweet_amazon_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new collection for Amazon tweets using the OpenAI embedding model and cosine as a distance metric\n",
    "collection = client.get_or_create_collection(name=\"tweet_amazon_collection\", \n",
    "                                             embedding_function=openai_ef,\n",
    "                                             metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding and storing into ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is embedding and storing all the tweets in the vector database.\n",
    "We are processing it by chunks to not reach the rate limit of OpenAI API for the embedding model.\n",
    "\"\"\"\n",
    "def chunk_dataframe(df, chunk_size):\n",
    "    \"\"\"Yield successive chunks of dataframe df with size chunk_size.\"\"\"\n",
    "    for start in range(0, len(df), chunk_size):\n",
    "        yield df.iloc[start:start + chunk_size]\n",
    "        \n",
    "chunk_size = 1000\n",
    "\n",
    "for i, chunk in enumerate(chunk_dataframe(df, chunk_size)):\n",
    "    print(f\"Processing chunk {i}\")\n",
    "    customer_tweets = chunk.customer_tweet.to_list()\n",
    "    company_tweets = [{\"company_tweet\": tweet} for tweet in chunk.company_tweet.to_list()]\n",
    "    ids_chunk = chunk.id.to_list()\n",
    "\n",
    "    # Process the current chunk\n",
    "    collection.add(\n",
    "        documents=customer_tweets,\n",
    "        metadatas=company_tweets,\n",
    "        ids=ids_chunk\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.peek()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flask_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
